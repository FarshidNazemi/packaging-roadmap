{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "219c91c3-89ee-445c-986e-db8eb745b472",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. General Problem Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d360e3fb-25ea-481f-9ad7-a328e0ab8a85",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8528e657-f6aa-4367-b3df-92d22f5e9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89a1d0-4385-4a8a-8125-8001faad6a29",
   "metadata": {},
   "source": [
    "## Import LCA matrices from OpenLCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "317cbd1c-cf83-4c5c-b020-f888f300682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_df = pd.read_csv(\"data/A.csv\", header=None)\n",
    "B_df = pd.read_csv(\"data/B.csv\", header=None)\n",
    "C_df = pd.read_csv(\"data/C.csv\", header=None)\n",
    "\n",
    "# Convert all string-looking numbers to floats\n",
    "A = A_df.apply(pd.to_numeric, errors='coerce').values\n",
    "B = B_df.apply(pd.to_numeric, errors='coerce').values\n",
    "C = C_df.apply(pd.to_numeric, errors='coerce').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a29d4e-491b-4db8-8940-f27b33fc2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_index_df = pd.read_csv(\"data/index_A.csv\")\n",
    "B_index_df = pd.read_csv(\"data/index_B.csv\")\n",
    "C_index_df = pd.read_csv(\"data/index_C.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3c91c-c688-4845-9dd3-0047aa3c84bc",
   "metadata": {},
   "source": [
    "## Removing Transportation (deregionalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0c573d-f4af-410f-b4b8-73eb44593f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_transport_df = pd.read_csv(\"data/Transportation_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14477a7b-c1c3-4db9-a17a-d6fd552317c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict mapping each provider name to all its indices in A_index_df\n",
    "mapping = A_index_df.groupby('provider name')['index'].apply(list)\n",
    "\n",
    "# build a single flat list of all matching indices for the foreground processes\n",
    "matched_indices_transport = [\n",
    "    idx\n",
    "    for name in A_transport_df['provider name']\n",
    "    if name in mapping\n",
    "    for idx in mapping[name]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3185e174-16e8-4be7-b1e4-bb93bfdba5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# matched_indices_transport is the list of indices to remove\n",
    "to_drop = np.array(sorted(set(matched_indices_transport), key=int))\n",
    "\n",
    "# 1) Remove from A_index_df\n",
    "mask_keep = ~A_index_df['index'].isin(to_drop)\n",
    "A_index_df = A_index_df.loc[mask_keep].copy()\n",
    "\n",
    "# 2) Remove corresponding rows and columns from A\n",
    "A = np.delete(A, to_drop, axis=0)  # remove rows\n",
    "A = np.delete(A, to_drop, axis=1)  # remove columns\n",
    "\n",
    "# 3) Remove the same columns from B (keep rows)\n",
    "B = np.delete(B, to_drop, axis=1)\n",
    "\n",
    "# 4) Reset the index column in A_index_df\n",
    "A_index_df['index'] = np.arange(len(A_index_df), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c9543-2d28-4c36-9e6f-02c4f9afdf8c",
   "metadata": {},
   "source": [
    "## Aggregating electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d9677d-e30f-49fd-9592-85e39589f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_elec_df = pd.read_csv(\"data/Electricity_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1243f655-d9ab-449e-b82c-804562147bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs assumed:\n",
    "# A : numeric numpy array (rows x cols)\n",
    "# A_index_df : DataFrame with columns [\"index\", \"provider name\", \"flow name\", ...]\n",
    "# A_elec_df : DataFrame with column [\"provider name\"] listing all electricity providers\n",
    "# The indices in A_index_df[\"index\"] align with both row and column positions of A.\n",
    "\n",
    "# 0) Build the set of electricity provider names\n",
    "elec_names = set(A_elec_df['provider name'].dropna().astype(str).unique())\n",
    "\n",
    "# 1) Find their indices in A_index_df\n",
    "elec_idx = A_index_df.loc[A_index_df['provider name'].astype(str).isin(elec_names), 'index'].astype(int).unique()\n",
    "\n",
    "# 2) Locate the mix row index (must exist)\n",
    "mix_name = \"Electricity Mix (Global)\"\n",
    "mix_rows = A_index_df.loc[A_index_df['provider name'] == mix_name, 'index'].astype(int).unique()\n",
    "if len(mix_rows) == 0:\n",
    "    raise ValueError(\"Electricity Mix (Global) not found in A_index_df['provider name'].\")\n",
    "mix_idx = int(mix_rows[0])\n",
    "\n",
    "# Ensure the mix row is not purged\n",
    "elec_idx_set = set(map(int, elec_idx))\n",
    "elec_idx_wo_mix = sorted(elec_idx_set - {mix_idx})\n",
    "\n",
    "# 3) Aggregate: add all electricity rows (except the mix row) into the mix row, column-wise\n",
    "if len(elec_idx_wo_mix) > 0:\n",
    "    # in case of NaNs\n",
    "    add_block = np.nansum(A[elec_idx_wo_mix, :], axis=0)\n",
    "    A[mix_idx, :] = np.nan_to_num(A[mix_idx, :]) + np.nan_to_num(add_block)\n",
    "\n",
    "# 4) Decide what to drop\n",
    "rows_to_drop = np.array(elec_idx_wo_mix, dtype=int)            # drop electricity rows except the mix row\n",
    "cols_to_drop = np.array(elec_idx_wo_mix, dtype=int)            # drop electricity columns except the mix column\n",
    "\n",
    "# (Optionally also drop the mix COLUMN; keep it if you want to retain that process as a column)\n",
    "# To ALSO drop the mix column, uncomment the next line:\n",
    "# cols_to_drop = np.array(sorted(elec_idx_set), dtype=int)\n",
    "\n",
    "# 5) Remove rows/columns from A\n",
    "if rows_to_drop.size > 0:\n",
    "    A = np.delete(A, rows_to_drop, axis=0)\n",
    "if cols_to_drop.size > 0:\n",
    "    A = np.delete(A, cols_to_drop, axis=1)\n",
    "\n",
    "# 6) Remove the same rows from A_index_df (only rows; columns in A_index_df are metadata)\n",
    "if len(elec_idx_wo_mix) > 0:\n",
    "    keep_mask = ~A_index_df['index'].astype(int).isin(elec_idx_wo_mix)\n",
    "    A_index_df = A_index_df.loc[keep_mask].copy()\n",
    "\n",
    "# 7) Reset the \"index\" column in A_index_df to reflect 0..n-1 after deletions\n",
    "A_index_df['index'] = np.arange(len(A_index_df), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002f8f6-b7a2-457b-84fd-122433189943",
   "metadata": {},
   "source": [
    "## Identifying background flows for cost calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6abc3af9-5e07-48e8-80bf-86359dfc5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_foreground_df = pd.read_csv(\"data/Foreground_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e88ff9d5-13b0-4b33-9b18-45ea8daeb086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Helper for consistent comparison\n",
    "norm = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# Normalize keys\n",
    "A_index_df = A_index_df.copy()\n",
    "A_foreground_df = A_foreground_df.copy()\n",
    "A_index_df['provider_key'] = A_index_df['provider name'].map(norm)\n",
    "A_foreground_df['provider_key'] = A_foreground_df['provider name'].map(norm)\n",
    "\n",
    "# Build mapping from provider -> indices\n",
    "idx_map = (\n",
    "    A_index_df\n",
    "    .groupby('provider_key')['index']\n",
    "    .apply(lambda s: list(map(int, s)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Foreground indices (to exclude later)\n",
    "matched_indices = sorted({\n",
    "    idx\n",
    "    for key in A_foreground_df['provider_key'].unique()\n",
    "    for idx in idx_map.get(key, [])\n",
    "})\n",
    "\n",
    "# Example: build all_nonzero from the numeric matrix A\n",
    "# (take all row indices with nonzero entries across the columns in matched_indices)\n",
    "all_nonzero = set()\n",
    "for col in matched_indices:\n",
    "    all_nonzero.update(np.nonzero(A[:, col])[0])\n",
    "\n",
    "# Remove overlap\n",
    "foreground_set = set(matched_indices)\n",
    "all_nonzero_set = {int(x) for x in all_nonzero}\n",
    "filtered_nonzero_rows = sorted(all_nonzero_set - foreground_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4a51dd-0bce-412e-8565-2546b418a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = A_index_df[A_index_df['index'].isin(filtered_nonzero_rows)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca834235-cc09-43db-95ee-bad708c136e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('filtered_nonzero_rows_with_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8cb8fc-75c1-429c-9a9d-60caabad1851",
   "metadata": {},
   "source": [
    "## Importing financial data for cost calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b92bafae-b1e8-44f6-9435-77b2bc891ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df = pd.read_csv(\"data/Financial.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be46d0-dd00-4f59-8bc9-def3f14e784a",
   "metadata": {},
   "source": [
    "# 2. Static Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4fa3b-a1dd-4630-99df-bcce5a4250ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1. Base Case (Linear Fossil Economy in 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ed06f-ce44-49d6-854f-53c5a8298b2f",
   "metadata": {},
   "source": [
    "### Electricity Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0063c7c-bc37-44ed-b6ed-c335a6b23731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Electricity Mix for 2025\n",
    "electricity_mix_df = pd.read_csv(\"data/electricity_mix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09efeeff-2c94-4c7c-b4a9-f296bed8dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Helper to normalize keys (to avoid case/space mismatches)\n",
    "norm = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# Normalize provider names in both DataFrames\n",
    "A_index_df = A_index_df.copy()\n",
    "electricity_mix_df = electricity_mix_df.copy()\n",
    "A_index_df['provider_key'] = A_index_df['provider name'].map(norm)\n",
    "electricity_mix_df['provider_key'] = electricity_mix_df['provider name'].map(norm)\n",
    "\n",
    "# Find the column index for \"Electricity Mix (Global)\"\n",
    "mix_key = norm(\"Electricity Mix (Global)\")\n",
    "mix_idx_arr = A_index_df.loc[A_index_df['provider_key'] == mix_key, 'index'].astype(int).values\n",
    "if len(mix_idx_arr) == 0:\n",
    "    raise ValueError(\"'Electricity Mix (Global)' not found in A_index_df['provider name']\")\n",
    "mix_col = int(mix_idx_arr[0])\n",
    "\n",
    "# Iterate over providers in electricity_mix_df and assign values into A\n",
    "for _, row in electricity_mix_df.iterrows():\n",
    "    prov_key = row['provider_key']\n",
    "    energy_val = row['2025 Energy Mix']\n",
    "\n",
    "    # find the row index (from A_index_df) for this provider\n",
    "    idxs = A_index_df.loc[A_index_df['provider_key'] == prov_key, 'index'].astype(int).values\n",
    "    for ridx in idxs:\n",
    "        A[ridx, mix_col] = energy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c209732-7f9e-439c-8b57-c85830ade9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1432"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[int(A_index_df.loc[A_index_df[\"provider name\"]==\"Electricity, hydropower (life cycle)\",\"index\"].iloc[0]),\n",
    "  int(A_index_df.loc[A_index_df[\"provider name\"]==\"Electricity Mix (Global)\",\"index\"].iloc[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118e6ab-699d-4d6e-ab32-7fd06fff9c40",
   "metadata": {},
   "source": [
    "### Collection and Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "925efc39-ff11-4ab6-ba19-06ffd143b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "packaging_types_df = pd.read_csv(\"data/packaging_types.csv\")\n",
    "collection_recyclate_df = pd.read_csv(\"data/collection_Recyclate.csv\")\n",
    "collection_msw_df = pd.read_csv(\"data/collection_MSW.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e680a17-1e7d-4799-8326-dd6ec1eff065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- helpers ----\n",
    "norm = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# defensive copies + normalized keys\n",
    "A_index_df = A_index_df.copy()\n",
    "packaging_types_df = packaging_types_df.copy()\n",
    "collection_recyclate_df = collection_recyclate_df.copy()\n",
    "\n",
    "A_index_df['provider_key'] = A_index_df['provider name'].map(norm)\n",
    "packaging_types_df['provider_key'] = packaging_types_df['provider name'].map(norm)\n",
    "collection_recyclate_df['provider_key'] = collection_recyclate_df['provider name'].map(norm)\n",
    "\n",
    "# map provider -> list of integer indices in A_index_df[\"index\"]\n",
    "idx_map = (\n",
    "    A_index_df.groupby('provider_key')['index']\n",
    "    .apply(lambda s: list(map(int, s)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# 1) PACKAGING: match providers and store their indices\n",
    "packaging_keys = set(packaging_types_df['provider_key'].dropna().unique())\n",
    "packaging_indices = sorted({idx for k in packaging_keys for idx in idx_map.get(k, [])})\n",
    "\n",
    "# 2) find the column index for \"Use & Collection\"\n",
    "use_col_key = norm(\"Use & Collection\")\n",
    "use_col_arr = A_index_df.loc[A_index_df['provider_key'] == use_col_key, 'index'].astype(int).values\n",
    "if len(use_col_arr) == 0:\n",
    "    raise ValueError('\"Use & Collection\" not found in A_index_df[\"provider name\"].')\n",
    "use_col = int(use_col_arr[0])\n",
    "\n",
    "# 3) Build X (absolute values from A at packaging rows, Use & Collection column), keyed by provider\n",
    "#    If a provider maps to multiple row indices, we take the value per row; but we store by provider_key for alignment.\n",
    "X_by_key = {}\n",
    "for k in packaging_keys:\n",
    "    rows = idx_map.get(k, [])\n",
    "    if not rows:\n",
    "        continue\n",
    "    # if multiple rows for same provider key, take the first (or sum; pick logic as needed)\n",
    "    r0 = int(rows[0])\n",
    "    X_by_key[k] = abs(float(A[r0, use_col]))\n",
    "\n",
    "# 4) COLLECTION-RECYCLATE: match providers & store their indices and Y values\n",
    "collection_keys = set(collection_recyclate_df['provider_key'].dropna().unique())\n",
    "collection_indices = sorted({idx for k in collection_keys for idx in idx_map.get(k, [])})\n",
    "\n",
    "# pull Y for each provider key (Linear Economy)\n",
    "Y_by_key = (\n",
    "    collection_recyclate_df\n",
    "    .dropna(subset=['provider_key'])\n",
    "    .groupby('provider_key')['Linear Economy']\n",
    "    .first()  # if duplicates, take the first; adjust if you need sum/mean\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# 5) Assign back to A: value = X * Y for each matching provider (aligned by provider_key)\n",
    "for k in collection_keys:\n",
    "    if k not in Y_by_key or k not in idx_map:\n",
    "        continue\n",
    "    # If this provider wasn't in packaging (no X), treat X as 0 (or skip)\n",
    "    X_val = X_by_key.get(k, 0.0)\n",
    "    Y_val = float(Y_by_key[k])\n",
    "\n",
    "    for r in idx_map[k]:\n",
    "        A[int(r), use_col] = X_val * Y_val\n",
    "\n",
    "# --- stored items you asked for ---\n",
    "# packaging_indices  -> indices for matched providers from packaging_types_df\n",
    "# use_col            -> the \"Use & Collection\" column index in A\n",
    "# collection_indices -> indices for matched providers from collection_recyclate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5003d2b-de4a-4ffc-8190-ca922780fbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[int(A_index_df.loc[A_index_df[\"provider name\"]==\"High-tech Sorting, Collected HDPE Drinking Bottles\",\"index\"].iloc[0]),\n",
    "  int(A_index_df.loc[A_index_df[\"provider name\"]==\"Use & Collection\",\"index\"].iloc[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "788e1bdf-ee0e-42c9-8f39-1e00690084bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- helpers ----\n",
    "norm = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# defensive copies + normalized keys\n",
    "A_index_df = A_index_df.copy()\n",
    "packaging_types_df = packaging_types_df.copy()\n",
    "collection_msw_df = collection_msw_df.copy()\n",
    "\n",
    "A_index_df['provider_key'] = A_index_df['provider name'].map(norm)\n",
    "packaging_types_df['provider_key'] = packaging_types_df['provider name'].map(norm)\n",
    "collection_msw_df['provider_key'] = collection_msw_df['provider name'].map(norm)\n",
    "\n",
    "# map provider -> list of integer indices in A_index_df[\"index\"]\n",
    "idx_map = (\n",
    "    A_index_df.groupby('provider_key')['index']\n",
    "    .apply(lambda s: list(map(int, s)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# 1) PACKAGING: match providers and store their indices\n",
    "packaging_keys = set(packaging_types_df['provider_key'].dropna().unique())\n",
    "packaging_indices = sorted({idx for k in packaging_keys for idx in idx_map.get(k, [])})\n",
    "\n",
    "# 2) find the column index for \"Use & Collection\"\n",
    "use_col_key = norm(\"Use & Collection\")\n",
    "use_col_arr = A_index_df.loc[A_index_df['provider_key'] == use_col_key, 'index'].astype(int).values\n",
    "if len(use_col_arr) == 0:\n",
    "    raise ValueError('\"Use & Collection\" not found in A_index_df[\"provider name\"].')\n",
    "use_col = int(use_col_arr[0])\n",
    "\n",
    "# 3) Build X (absolute values from A at packaging rows, Use & Collection column), keyed by provider\n",
    "X_by_key = {}\n",
    "for k in packaging_keys:\n",
    "    rows = idx_map.get(k, [])\n",
    "    if not rows:\n",
    "        continue\n",
    "    r0 = int(rows[0])  # if multiple rows per provider, adjust (sum/mean) as needed\n",
    "    X_by_key[k] = abs(float(A[r0, use_col]))\n",
    "\n",
    "# 4) COLLECTION-MSW: match providers & store their indices and Y values\n",
    "collection_keys = set(collection_msw_df['provider_key'].dropna().unique())\n",
    "collection_indices = sorted({idx for k in collection_keys for idx in idx_map.get(k, [])})\n",
    "\n",
    "# pull Y for each provider key (Linear Economy)\n",
    "Y_by_key = (\n",
    "    collection_msw_df\n",
    "    .dropna(subset=['provider_key'])\n",
    "    .groupby('provider_key')['Linear Economy']\n",
    "    .first()  # if duplicates, take the first; change to sum()/mean() if needed\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# 5) Assign back to A: value = X * Y for each matching provider (aligned by provider_key)\n",
    "for k in collection_keys:\n",
    "    if k not in Y_by_key or k not in idx_map:\n",
    "        continue\n",
    "    X_val = X_by_key.get(k, 0.0)    # if provider not in packaging, X defaults to 0\n",
    "    Y_val = float(Y_by_key[k])\n",
    "\n",
    "    for r in idx_map[k]:\n",
    "        A[int(r), use_col] = X_val * Y_val\n",
    "\n",
    "# --- Stored results ---\n",
    "# packaging_indices  -> indices for matched providers from packaging_types_df\n",
    "# use_col            -> the \"Use & Collection\" column index in A\n",
    "# collection_indices -> indices for matched providers from collection_msw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddf9ed47-f593-41ff-a3d2-8c7daf7e5a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[int(A_index_df.loc[A_index_df[\"provider name\"]==\"Disposal, LDPE Food Packaging Film (small format)\",\"index\"].iloc[0]),\n",
    "  int(A_index_df.loc[A_index_df[\"provider name\"]==\"Use & Collection\",\"index\"].iloc[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e8829be-57b6-4279-bd7f-ba20aa9a6425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In packaging_types_df? False\n",
      "X_by_key has it? False\n",
      "X value: None\n",
      "Existing A[row,use_col]: 0.0\n"
     ]
    }
   ],
   "source": [
    "target = \"Disposal, LDPE Food Packaging Film (small format)\"\n",
    "k = str(target).strip().casefold()\n",
    "\n",
    "print(\"In packaging_types_df?\", k in packaging_types_df['provider name'].str.strip().str.casefold().unique())\n",
    "print(\"X_by_key has it?\", k in X_by_key)\n",
    "print(\"X value:\", X_by_key.get(k, None))\n",
    "\n",
    "# Whatâ€™s currently in A at that row & Use & Collection col?\n",
    "row_idx = int(A_index_df.loc[A_index_df[\"provider name\"]==target,\"index\"].iloc[0])\n",
    "use_col = int(A_index_df.loc[A_index_df[\"provider name\"]==\"Use & Collection\",\"index\"].iloc[0])\n",
    "print(\"Existing A[row,use_col]:\", A[row_idx, use_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbaa381a-b40f-453a-b8e2-65411b1f73f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "norm = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# normalize\n",
    "A_index_df = A_index_df.copy()\n",
    "collection_msw_df = collection_msw_df.copy()\n",
    "A_index_df['provider_key'] = A_index_df['provider name'].map(norm)\n",
    "collection_msw_df['provider_key'] = collection_msw_df['provider name'].map(norm)\n",
    "\n",
    "# map provider -> list of indices (rows) in A_index_df[\"index\"]\n",
    "idx_map = (\n",
    "    A_index_df.groupby('provider_key')['index']\n",
    "    .apply(lambda s: list(map(int, s)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# find Use & Collection column index\n",
    "use_col_key = norm(\"Use & Collection\")\n",
    "use_col_arr = A_index_df.loc[A_index_df['provider_key'] == use_col_key, 'index'].astype(int).values\n",
    "if len(use_col_arr) == 0:\n",
    "    raise ValueError('\"Use & Collection\" not found in A_index_df[\"provider name\"].')\n",
    "use_col = int(use_col_arr[0])\n",
    "\n",
    "# Y from collection_msw_df (\"Linear Economy\")\n",
    "Y_by_key = (\n",
    "    collection_msw_df\n",
    "    .dropna(subset=['provider_key'])\n",
    "    .groupby('provider_key')['Linear Economy']\n",
    "    .first()\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# update A: for each matched provider row r, set A[r, use_col] = abs(A[r, use_col]) * Y\n",
    "for k, Y_val in Y_by_key.items():\n",
    "    for r in idx_map.get(k, []):\n",
    "        r = int(r)\n",
    "        X_val = abs(float(A[r, use_col]))   # <-- compute X from A at that row\n",
    "        A[r, use_col] = X_val * float(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed9d18bf-b52f-47a9-81af-cfb37b3c1f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[int(A_index_df.loc[A_index_df[\"provider name\"]==\"Disposal, LDPE Food Packaging Film (small format)\",\"index\"].iloc[0]),\n",
    "  int(A_index_df.loc[A_index_df[\"provider name\"]==\"Use & Collection\",\"index\"].iloc[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78a9dc4c-fc62-406b-af98-7b46d3c75763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After update: 0.0\n"
     ]
    }
   ],
   "source": [
    "p = \"Disposal, LDPE Food Packaging Film (small format)\"\n",
    "r = int(A_index_df.loc[A_index_df[\"provider name\"]==p, \"index\"].iloc[0])\n",
    "c = int(A_index_df.loc[A_index_df[\"provider name\"]==\"Use & Collection\", \"index\"].iloc[0])\n",
    "print(\"After update:\", A[r, c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e75f8e89-391b-4375-83b9-8e446fc8d326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set X (absolute values from A at packaging rows, Use & Collection column):\n",
      "PVC Other Non-food Rigid: 0.013\n",
      "HDPE Food Bottles: 0.008\n",
      "PP Food Bottles: 0.004\n",
      "PS Other Food Rigid: 0.025\n",
      "HDPE Drinking Bottles: 0.02\n",
      "PET Other Non-food Rigid: 0.02\n",
      "PP Food Packaging Film (med-large format): 0.026\n",
      "PP Other Food Rigid: 0.138\n",
      "Multi-material Food Bottles: 0.028\n",
      "PET Other Food Rigid: 0.025\n",
      "HDPE Other Food Rigid : 0.027\n",
      "PET Non-food Bottles: 0.014\n",
      "PET Food Bottles: 0.008\n",
      "Multi-material Food Packaging Film (small format): 0.07\n",
      "LDPE Food Packaging Film (med-large format): 0.124\n",
      "PP Food Packaging Film (small format): 0.005\n",
      "PP Non-food Bottles: 0.005\n",
      "PVC Other Food Rigid: 0.011\n",
      "HDPE Other Non-food Rigid: 0.01\n",
      "HDPE Non-food Bottles: 0.056\n",
      "Multi-material Food Packaging Film (med-large format): 0.007\n",
      "LDPE Food Packaging Film (small format): 0.025\n",
      "PET Drinking Bottles: 0.182\n",
      "Multi-material Non-food Packaging Film: 0.025\n",
      "LDPE Non-food Packaging Films : 0.082\n",
      "PP Non-food Packaging Films : 0.018\n",
      "PP Other Non-food Rigid: 0.023\n"
     ]
    }
   ],
   "source": [
    "# after building X_by_key\n",
    "print(\"Set X (absolute values from A at packaging rows, Use & Collection column):\")\n",
    "for k, v in X_by_key.items():\n",
    "    prov_name = A_index_df.loc[A_index_df['provider_key'] == k, 'provider name'].iloc[0]\n",
    "    print(f\"{prov_name}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c853d0d-02f3-432a-86ee-e895b5922598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Y (Linear Economy values from collection_recyclate_df):\n",
      "Disposal, HDPE Drinking Bottles: 0.96\n",
      "Disposal, HDPE Food Bottles: 0.96\n",
      "Disposal, HDPE Non-food Bottles: 0.96\n",
      "Disposal, HDPE Other Food Rigid : 0.96\n",
      "Disposal, HDPE Other Non-food Rigid: 0.96\n",
      "Disposal, LDPE Food Packaging Film (med-large format): 0.81\n",
      "Disposal, LDPE Food Packaging Film (small format): 0.8\n",
      "Disposal, LDPE Non-food Packaging Films : 0.81\n",
      "Disposal, Multi-material Food Bottles: 0.78\n",
      "Disposal, Multi-material Food Packaging Film (med-large format): 0.78\n",
      "Disposal, Multi-material Food Packaging Film (small format): 0.78\n",
      "Disposal, Multi-material Non-food Packaging Film: 0.78\n",
      "Disposal, PET Drinking Bottles: 0.96\n",
      "Disposal, PET Food Bottles: 0.96\n",
      "Disposal, PET Non-food Bottles: 0.96\n",
      "Disposal, PET Other Food Rigid: 0.96\n",
      "Disposal, PET Other Non-food Rigid: 0.96\n",
      "Disposal, PP Food Bottles: 0.96\n",
      "Disposal, PP Food Packaging Film (med-large format): 0.81\n",
      "Disposal, PP Food Packaging Film (small format): 0.8\n",
      "Disposal, PP Non-food Bottles: 0.96\n",
      "Disposal, PP Non-food Packaging Films : 0.81\n",
      "Disposal, PP Other Food Rigid: 0.96\n",
      "Disposal, PP Other Non-food Rigid: 0.96\n",
      "Disposal, PS Other Food Rigid: 0.96\n",
      "Disposal, PVC Other Food Rigid: 0.96\n",
      "Disposal, PVC Other Non-food Rigid: 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Set Y (Linear Economy values from collection_recyclate_df):\")\n",
    "for k, v in Y_by_key.items():\n",
    "    prov_name = A_index_df.loc[A_index_df['provider_key'] == k, 'provider name'].iloc[0]\n",
    "    print(f\"{prov_name}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a621066c-fc3c-43e2-a3ca-4c9f01c1cc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row index (r): 102\n",
      "Use&Collection col (c): 0\n",
      "X before update (A[r,c]): 0.0\n",
      "Y (Linear Economy): 0.8\n",
      "A[r,c] after update: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "target = \"Disposal, LDPE Food Packaging Film (small format)\"\n",
    "use_col_name = \"Use & Collection\"\n",
    "\n",
    "norm = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# indexes\n",
    "r_matches = A_index_df.loc[A_index_df[\"provider name\"] == target, \"index\"].astype(int).tolist()\n",
    "c_matches = A_index_df.loc[A_index_df[\"provider name\"] == use_col_name, \"index\"].astype(int).tolist()\n",
    "assert r_matches and c_matches, \"Row/column not found.\"\n",
    "\n",
    "r = r_matches[0]\n",
    "c = c_matches[0]\n",
    "\n",
    "# keys\n",
    "A_index_df[\"provider_key\"] = A_index_df[\"provider name\"].map(norm)\n",
    "collection_msw_df[\"provider_key\"] = collection_msw_df[\"provider name\"].map(norm)\n",
    "k = norm(target)\n",
    "\n",
    "# Y from MSW\n",
    "Y_series = collection_msw_df.loc[collection_msw_df[\"provider_key\"] == k, \"Linear Economy\"]\n",
    "Y_val = float(Y_series.iloc[0]) if not Y_series.empty else None\n",
    "\n",
    "# X from A at (r, use_col)\n",
    "X_val = float(A[r, c])\n",
    "\n",
    "print(\"Row index (r):\", r)\n",
    "print(\"Use&Collection col (c):\", c)\n",
    "print(\"X before update (A[r,c]):\", X_val)\n",
    "print(\"Y (Linear Economy):\", Y_val)\n",
    "\n",
    "# what did our update write?\n",
    "print(\"A[r,c] after update:\", float(A[r, c]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01072a78-e709-4531-9f63-f964d771b2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
