{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "219c91c3-89ee-445c-986e-db8eb745b472",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. General Problem Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d360e3fb-25ea-481f-9ad7-a328e0ab8a85",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8528e657-f6aa-4367-b3df-92d22f5e9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89a1d0-4385-4a8a-8125-8001faad6a29",
   "metadata": {},
   "source": [
    "## Import LCA matrices from OpenLCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "317cbd1c-cf83-4c5c-b020-f888f300682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_df = pd.read_csv(\"data/A.csv\", header=None)\n",
    "B_df = pd.read_csv(\"data/B.csv\", header=None)\n",
    "C_df = pd.read_csv(\"data/C.csv\", header=None)\n",
    "\n",
    "# Convert all string-looking numbers to floats\n",
    "A = A_df.apply(pd.to_numeric, errors='coerce').values\n",
    "B = B_df.apply(pd.to_numeric, errors='coerce').values\n",
    "C = C_df.apply(pd.to_numeric, errors='coerce').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a29d4e-491b-4db8-8940-f27b33fc2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_index_df = pd.read_csv(\"data/index_A.csv\")\n",
    "B_index_df = pd.read_csv(\"data/index_B.csv\")\n",
    "C_index_df = pd.read_csv(\"data/index_C.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3c91c-c688-4845-9dd3-0047aa3c84bc",
   "metadata": {},
   "source": [
    "## Removing Transportation (deregionalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0c573d-f4af-410f-b4b8-73eb44593f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_transport_df = pd.read_csv(\"data/Transportation_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14477a7b-c1c3-4db9-a17a-d6fd552317c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict mapping each provider name to all its indices in A_index_df\n",
    "mapping = A_index_df.groupby('provider name')['index'].apply(list)\n",
    "\n",
    "# build a single flat list of all matching indices for the foreground processes\n",
    "matched_indices_transport = [\n",
    "    idx\n",
    "    for name in A_transport_df['provider name']\n",
    "    if name in mapping\n",
    "    for idx in mapping[name]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3185e174-16e8-4be7-b1e4-bb93bfdba5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# matched_indices_transport is the list of indices to remove\n",
    "to_drop = np.array(sorted(set(matched_indices_transport), key=int))\n",
    "\n",
    "# 1) Remove from A_index_df\n",
    "mask_keep = ~A_index_df['index'].isin(to_drop)\n",
    "A_index_df = A_index_df.loc[mask_keep].copy()\n",
    "\n",
    "# 2) Remove corresponding rows and columns from A\n",
    "A = np.delete(A, to_drop, axis=0)  # remove rows\n",
    "A = np.delete(A, to_drop, axis=1)  # remove columns\n",
    "\n",
    "# 3) Remove the same columns from B (keep rows)\n",
    "B = np.delete(B, to_drop, axis=1)\n",
    "\n",
    "# 4) Reset the index column in A_index_df\n",
    "A_index_df['index'] = np.arange(len(A_index_df), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c9543-2d28-4c36-9e6f-02c4f9afdf8c",
   "metadata": {},
   "source": [
    "## Aggregating electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d9677d-e30f-49fd-9592-85e39589f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_elec_df = pd.read_csv(\"data/Electricity_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1243f655-d9ab-449e-b82c-804562147bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs assumed:\n",
    "# A : numeric numpy array (rows x cols)\n",
    "# A_index_df : DataFrame with columns [\"index\", \"provider name\", \"flow name\", ...]\n",
    "# A_elec_df : DataFrame with column [\"provider name\"] listing all electricity providers\n",
    "# The indices in A_index_df[\"index\"] align with both row and column positions of A.\n",
    "\n",
    "# 0) Build the set of electricity provider names\n",
    "elec_names = set(A_elec_df['provider name'].dropna().astype(str).unique())\n",
    "\n",
    "# 1) Find their indices in A_index_df\n",
    "elec_idx = A_index_df.loc[A_index_df['provider name'].astype(str).isin(elec_names), 'index'].astype(int).unique()\n",
    "\n",
    "# 2) Locate the mix row index (must exist)\n",
    "mix_name = \"Electricity Mix (Global)\"\n",
    "mix_rows = A_index_df.loc[A_index_df['provider name'] == mix_name, 'index'].astype(int).unique()\n",
    "if len(mix_rows) == 0:\n",
    "    raise ValueError(\"Electricity Mix (Global) not found in A_index_df['provider name'].\")\n",
    "mix_idx = int(mix_rows[0])\n",
    "\n",
    "# Ensure the mix row is not purged\n",
    "elec_idx_set = set(map(int, elec_idx))\n",
    "elec_idx_wo_mix = sorted(elec_idx_set - {mix_idx})\n",
    "\n",
    "# 3) Aggregate: add all electricity rows (except the mix row) into the mix row, column-wise\n",
    "if len(elec_idx_wo_mix) > 0:\n",
    "    # in case of NaNs\n",
    "    add_block = np.nansum(A[elec_idx_wo_mix, :], axis=0)\n",
    "    A[mix_idx, :] = np.nan_to_num(A[mix_idx, :]) + np.nan_to_num(add_block)\n",
    "\n",
    "# 4) Decide what to drop\n",
    "rows_to_drop = np.array(elec_idx_wo_mix, dtype=int)            # drop electricity rows except the mix row\n",
    "cols_to_drop = np.array(elec_idx_wo_mix, dtype=int)            # drop electricity columns except the mix column\n",
    "\n",
    "# (Optionally also drop the mix COLUMN; keep it if you want to retain that process as a column)\n",
    "# To ALSO drop the mix column, uncomment the next line:\n",
    "# cols_to_drop = np.array(sorted(elec_idx_set), dtype=int)\n",
    "\n",
    "# 5) Remove rows/columns from A\n",
    "if rows_to_drop.size > 0:\n",
    "    A = np.delete(A, rows_to_drop, axis=0)\n",
    "if cols_to_drop.size > 0:\n",
    "    A = np.delete(A, cols_to_drop, axis=1)\n",
    "\n",
    "# 6) Remove the same rows from A_index_df (only rows; columns in A_index_df are metadata)\n",
    "if len(elec_idx_wo_mix) > 0:\n",
    "    keep_mask = ~A_index_df['index'].astype(int).isin(elec_idx_wo_mix)\n",
    "    A_index_df = A_index_df.loc[keep_mask].copy()\n",
    "\n",
    "# 7) Reset the \"index\" column in A_index_df to reflect 0..n-1 after deletions\n",
    "A_index_df['index'] = np.arange(len(A_index_df), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002f8f6-b7a2-457b-84fd-122433189943",
   "metadata": {},
   "source": [
    "## Identifying background flows for cost calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6abc3af9-5e07-48e8-80bf-86359dfc5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_foreground_df = pd.read_csv(\"data/Foreground_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e88ff9d5-13b0-4b33-9b18-45ea8daeb086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Helper for consistent comparison\n",
    "norm = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# Normalize keys\n",
    "A_index_df = A_index_df.copy()\n",
    "A_foreground_df = A_foreground_df.copy()\n",
    "A_index_df['provider_key'] = A_index_df['provider name'].map(norm)\n",
    "A_foreground_df['provider_key'] = A_foreground_df['provider name'].map(norm)\n",
    "\n",
    "# Build mapping from provider -> indices\n",
    "idx_map = (\n",
    "    A_index_df\n",
    "    .groupby('provider_key')['index']\n",
    "    .apply(lambda s: list(map(int, s)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Foreground indices (to exclude later)\n",
    "matched_indices = sorted({\n",
    "    idx\n",
    "    for key in A_foreground_df['provider_key'].unique()\n",
    "    for idx in idx_map.get(key, [])\n",
    "})\n",
    "\n",
    "# Example: build all_nonzero from the numeric matrix A\n",
    "# (take all row indices with nonzero entries across the columns in matched_indices)\n",
    "all_nonzero = set()\n",
    "for col in matched_indices:\n",
    "    all_nonzero.update(np.nonzero(A[:, col])[0])\n",
    "\n",
    "# Remove overlap\n",
    "foreground_set = set(matched_indices)\n",
    "all_nonzero_set = {int(x) for x in all_nonzero}\n",
    "filtered_nonzero_rows = sorted(all_nonzero_set - foreground_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4a51dd-0bce-412e-8565-2546b418a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = A_index_df[A_index_df['index'].isin(filtered_nonzero_rows)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca834235-cc09-43db-95ee-bad708c136e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('filtered_nonzero_rows_with_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8cb8fc-75c1-429c-9a9d-60caabad1851",
   "metadata": {},
   "source": [
    "## Importing financial data for cost calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b92bafae-b1e8-44f6-9435-77b2bc891ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df = pd.read_csv(\"data/Financial.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be46d0-dd00-4f59-8bc9-def3f14e784a",
   "metadata": {},
   "source": [
    "# 2. Static Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4fa3b-a1dd-4630-99df-bcce5a4250ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1. Base Case (Linear Fossil Economy in 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ed06f-ce44-49d6-854f-53c5a8298b2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Electricity Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0063c7c-bc37-44ed-b6ed-c335a6b23731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Electricity Mix for 2025\n",
    "electricity_mix_df = pd.read_csv(\"data/electricity_mix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09efeeff-2c94-4c7c-b4a9-f296bed8dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Helper to normalize keys (to avoid case/space mismatches)\n",
    "norm = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# Normalize provider names in both DataFrames\n",
    "A_index_df = A_index_df.copy()\n",
    "electricity_mix_df = electricity_mix_df.copy()\n",
    "A_index_df['provider_key'] = A_index_df['provider name'].map(norm)\n",
    "electricity_mix_df['provider_key'] = electricity_mix_df['provider name'].map(norm)\n",
    "\n",
    "# Find the column index for \"Electricity Mix (Global)\"\n",
    "mix_key = norm(\"Electricity Mix (Global)\")\n",
    "mix_idx_arr = A_index_df.loc[A_index_df['provider_key'] == mix_key, 'index'].astype(int).values\n",
    "if len(mix_idx_arr) == 0:\n",
    "    raise ValueError(\"'Electricity Mix (Global)' not found in A_index_df['provider name']\")\n",
    "mix_col = int(mix_idx_arr[0])\n",
    "\n",
    "# Iterate over providers in electricity_mix_df and assign values into A\n",
    "for _, row in electricity_mix_df.iterrows():\n",
    "    prov_key = row['provider_key']\n",
    "    energy_val = row['2025 Energy Mix']\n",
    "\n",
    "    # find the row index (from A_index_df) for this provider\n",
    "    idxs = A_index_df.loc[A_index_df['provider_key'] == prov_key, 'index'].astype(int).values\n",
    "    for ridx in idxs:\n",
    "        A[ridx, mix_col] = energy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c209732-7f9e-439c-8b57-c85830ade9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1432"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[int(A_index_df.loc[A_index_df[\"provider name\"]==\"Electricity, hydropower (life cycle)\",\"index\"].iloc[0]),\n",
    "  int(A_index_df.loc[A_index_df[\"provider name\"]==\"Electricity Mix (Global)\",\"index\"].iloc[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118e6ab-699d-4d6e-ab32-7fd06fff9c40",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Collection and Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "925efc39-ff11-4ab6-ba19-06ffd143b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "packaging_types_df = pd.read_csv(\"data/packaging_types.csv\")\n",
    "collection_recyclate_df = pd.read_csv(\"data/collection_Recyclate.csv\")\n",
    "collection_msw_df = pd.read_csv(\"data/collection_MSW.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0a621c7-06a2-4cdc-9622-bc3702bff381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ---- exact-key matcher (case/space insensitive, keeps stage prefixes) ----\n",
    "ekey = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# ---- copies + normalized keys ----\n",
    "A_index_df = A_index_df.copy()\n",
    "packaging_types_df = packaging_types_df.copy()\n",
    "collection_msw_df = collection_msw_df.copy()\n",
    "\n",
    "A_index_df[\"prov_exact\"]         = A_index_df[\"provider name\"].map(ekey)\n",
    "packaging_types_df[\"prov_exact\"] = packaging_types_df[\"provider name\"].map(ekey)\n",
    "collection_msw_df[\"prov_exact\"]  = collection_msw_df[\"provider name\"].map(ekey)\n",
    "\n",
    "# If you know the 3 mapping columns, set them here, e.g.:\n",
    "# mapping_cols = [\"dest_1\", \"dest_2\", \"dest_3\"]\n",
    "# Otherwise, auto-detect up to 3 string columns besides 'provider name'\n",
    "mapping_cols = [c for c in packaging_types_df.columns\n",
    "                if c not in (\"provider name\", \"prov_exact\")\n",
    "                and pd.api.types.is_string_dtype(packaging_types_df[c])][:3]\n",
    "if not mapping_cols:\n",
    "    raise ValueError(\"Couldn't detect mapping columns; please set 'mapping_cols' explicitly.\")\n",
    "\n",
    "# Normalize destination columns\n",
    "for col in mapping_cols:\n",
    "    packaging_types_df[col + \"_exact\"] = packaging_types_df[col].map(ekey)\n",
    "\n",
    "# provider name -> list of integer indices in A (rows/cols)\n",
    "idx_map_exact = (\n",
    "    A_index_df.groupby(\"prov_exact\")[\"index\"]\n",
    "              .apply(lambda s: list(map(int, s)))\n",
    "              .to_dict()\n",
    ")\n",
    "\n",
    "# \"Use & Collection\" column index\n",
    "use_col = int(A_index_df.loc[A_index_df[\"provider name\"]==\"Use & Collection\",\"index\"].iloc[0])\n",
    "\n",
    "# ---- X: abs(A[row, use_col]) per packaging provider (exact match) ----\n",
    "X_by_src = {}\n",
    "for k in packaging_types_df[\"prov_exact\"].dropna().unique():\n",
    "    rows = idx_map_exact.get(k, [])\n",
    "    if rows:\n",
    "        r0 = int(rows[0])  # if multiple rows per provider, change to sum/mean if needed\n",
    "        X_by_src[k] = abs(float(A[r0, use_col]))\n",
    "\n",
    "# ---- Y: MSW \"Linear Economy\" per provider (exact match) ----\n",
    "Y_by_key = (collection_msw_df.dropna(subset=[\"prov_exact\"])\n",
    "            .groupby(\"prov_exact\")[\"Linear Economy\"]\n",
    "            .first()\n",
    "            .to_dict())\n",
    "\n",
    "# ---- zero out destination cells we're going to rewrite (avoid accumulation on reruns) ----\n",
    "dest_rows = set()\n",
    "for _, row in packaging_types_df.iterrows():\n",
    "    for col in mapping_cols:\n",
    "        dk = row.get(col + \"_exact\", None)\n",
    "        if dk in idx_map_exact:\n",
    "            dest_rows.update(idx_map_exact[dk])\n",
    "if dest_rows:\n",
    "    A[list(dest_rows), use_col] = 0.0\n",
    "\n",
    "# ---- assign: A[row, use_col] += X * Y for each mapped destination (exact match) ----\n",
    "for _, row in packaging_types_df.iterrows():\n",
    "    src_k = row[\"prov_exact\"]\n",
    "    X     = X_by_src.get(src_k)\n",
    "    if X is None:\n",
    "        continue\n",
    "    for col in mapping_cols:\n",
    "        dk = row.get(col + \"_exact\", None)\n",
    "        if not dk:\n",
    "            continue\n",
    "        Y = Y_by_key.get(dk)\n",
    "        if Y is None or pd.isna(Y):\n",
    "            continue\n",
    "        contrib = float(abs(X) * float(Y))\n",
    "        for r in idx_map_exact.get(dk, []):\n",
    "            A[int(r), use_col] += contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a637468f-f855-4092-8a77-aaf3bd412721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021840000000000002"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[int(A_index_df.loc[A_index_df[\"provider name\"]==\"Disposal, Multi-material Food Bottles\",\"index\"].iloc[0]),\n",
    "  int(A_index_df.loc[A_index_df[\"provider name\"]==\"Use & Collection\",\"index\"].iloc[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bdc6ddb-8a03-4bfb-8c97-47de0ba52572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Recyclate pass: X * Y_recyclate added into A[:, use_col] ---\n",
    "\n",
    "collection_recyclate_df = collection_recyclate_df.copy()\n",
    "collection_recyclate_df[\"prov_exact\"] = collection_recyclate_df[\"provider name\"].map(ekey)\n",
    "\n",
    "# Y from recyclate\n",
    "Y_rec_by_key = (\n",
    "    collection_recyclate_df.dropna(subset=[\"prov_exact\"])\n",
    "    .groupby(\"prov_exact\")[\"Linear Economy\"]\n",
    "    .first()    # change to sum()/mean() if needed\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Optionally clear destination cells before this pass (default = keep MSW values and add recyclate)\n",
    "reset_dest = False\n",
    "if reset_dest:\n",
    "    rec_dest_rows = set()\n",
    "    for _, row in packaging_types_df.iterrows():\n",
    "        for col in mapping_cols:\n",
    "            dk = row.get(col + \"_exact\", None)\n",
    "            rec_dest_rows.update(idx_map_exact.get(dk, []))\n",
    "    if rec_dest_rows:\n",
    "        A[np.array(sorted(rec_dest_rows), dtype=int), use_col] = 0.0\n",
    "\n",
    "# Write: A[row, use_col] += X * Y_recyclate\n",
    "for _, row in packaging_types_df.iterrows():\n",
    "    src_k = row[\"prov_exact\"]\n",
    "    X = X_by_src.get(src_k)\n",
    "    if X is None:\n",
    "        continue\n",
    "    for col in mapping_cols:\n",
    "        dk = row.get(col + \"_exact\", None)\n",
    "        if not dk:\n",
    "            continue\n",
    "        Y = Y_rec_by_key.get(dk)\n",
    "        if Y is None or pd.isna(Y):\n",
    "            continue\n",
    "        contrib = float(abs(X) * float(Y))\n",
    "        for r in idx_map_exact.get(dk, []):\n",
    "            A[int(r), use_col] += contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13813ae7-1e2c-4572-9712-cac16fa3a29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[int(A_index_df.loc[A_index_df[\"provider name\"]==\"High-tech Sorting, Collected HDPE Drinking Bottles\",\"index\"].iloc[0]),\n",
    "  int(A_index_df.loc[A_index_df[\"provider name\"]==\"Use & Collection\",\"index\"].iloc[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff7b317-9f95-45f9-8f5d-a198cb125c2f",
   "metadata": {},
   "source": [
    "### Monomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84907181-084f-423e-afcb-25c5b3b62b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "monomers_decisions_df = pd.read_csv(\"data/monomers_decisions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c70d06a-a354-4162-8d7c-9d0eb9bfe69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 12 (row, col) cells in A; skipped 0 decision rows lacking matches or X.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- helper: normalize names for reliable matching ----\n",
    "ekey = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# ---- defensive copies + normalized keys ----\n",
    "A_index_df = A_index_df.copy()\n",
    "monomers_decisions_df = monomers_decisions_df.copy()\n",
    "\n",
    "A_index_df[\"prov_key\"] = A_index_df[\"provider name\"].map(ekey)\n",
    "monomers_decisions_df[\"col_key\"]  = monomers_decisions_df[\"Provider name\"].map(ekey)\n",
    "monomers_decisions_df[\"row_key\"]  = monomers_decisions_df[\"Input parameters names\"].map(ekey)\n",
    "\n",
    "# provider key -> list of integer indices in A (rows/cols)\n",
    "idx_map = (\n",
    "    A_index_df.groupby(\"prov_key\")[\"index\"]\n",
    "    .apply(lambda s: list(map(int, s)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# ensure \"Linear Economy\" is numeric\n",
    "monomers_decisions_df[\"Linear Economy\"] = pd.to_numeric(\n",
    "    monomers_decisions_df[\"Linear Economy\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# ---- apply updates: for each row in decisions, scale A[row_idx, col_idx] *= X ----\n",
    "n_pairs = 0\n",
    "skipped = 0\n",
    "\n",
    "for _, drow in monomers_decisions_df.iterrows():\n",
    "    x = drow[\"Linear Economy\"]\n",
    "    if pd.isna(x):\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    row_idxs = idx_map.get(drow[\"row_key\"], [])\n",
    "    col_idxs = idx_map.get(drow[\"col_key\"], [])\n",
    "\n",
    "    if not row_idxs or not col_idxs:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # multiply all combinations (row, col) by X\n",
    "    for ri in row_idxs:\n",
    "        for ci in col_idxs:\n",
    "            A[int(ri), int(ci)] = np.nan_to_num(A[int(ri), int(ci)]) * float(x)\n",
    "            n_pairs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35f4586b-7579-4f0d-9080-45eff0cd55aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[int(A_index_df.loc[A_index_df[\"provider name\"]==\"Ethylene production, fossil, steam cracker\",\"index\"].iloc[0]),\n",
    "  int(A_index_df.loc[A_index_df[\"provider name\"]==\"Ethylene\",\"index\"].iloc[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f2cba-97bc-432b-954c-d2fc62e5ce6d",
   "metadata": {},
   "source": [
    "### Carbon Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec4b673c-8033-40e4-b506-73baaf7ab563",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_capture_decisions_df = pd.read_csv(\"data/carbon_capture_decisions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f32d0b6f-787e-4517-9a3d-3ca555550713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carbon_capture_decisions_df: updated 6 cells; skipped 0 rows.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# normalize for reliable matching\n",
    "ekey = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# copies + keys\n",
    "A_index_df = A_index_df.copy()\n",
    "carbon_capture_decisions_df = carbon_capture_decisions_df.copy()\n",
    "\n",
    "A_index_df[\"prov_key\"] = A_index_df[\"provider name\"].map(ekey)\n",
    "carbon_capture_decisions_df[\"col_key\"] = carbon_capture_decisions_df[\"Provider name\"].map(ekey)\n",
    "carbon_capture_decisions_df[\"row_key\"] = carbon_capture_decisions_df[\"Input parameters names\"].map(ekey)\n",
    "\n",
    "# provider key -> list of integer indices (row/col) in A\n",
    "idx_map = (\n",
    "    A_index_df.groupby(\"prov_key\")[\"index\"]\n",
    "    .apply(lambda s: list(map(int, s)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# ensure numeric X\n",
    "carbon_capture_decisions_df[\"Linear Economy\"] = pd.to_numeric(\n",
    "    carbon_capture_decisions_df[\"Linear Economy\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# apply: for each decision row, A[row, col] *= X\n",
    "n_pairs = 0\n",
    "skipped = 0\n",
    "\n",
    "for _, d in carbon_capture_decisions_df.iterrows():\n",
    "    X = d[\"Linear Economy\"]\n",
    "    if pd.isna(X):\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    row_idxs = idx_map.get(d[\"row_key\"], [])\n",
    "    col_idxs = idx_map.get(d[\"col_key\"], [])\n",
    "\n",
    "    if not row_idxs or not col_idxs:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    for ri in row_idxs:\n",
    "        for ci in col_idxs:\n",
    "            A[int(ri), int(ci)] = np.nan_to_num(A[int(ri), int(ci)]) * float(X)\n",
    "            n_pairs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56328051-5a67-4133-a373-fe67a9f0b092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[int(A_index_df.loc[A_index_df[\"provider name\"]==\"Plastic Incineration CO2 to the atmosphere\",\"index\"].iloc[0]),\n",
    "  int(A_index_df.loc[A_index_df[\"provider name\"]==\"Plastic Incineration CO2\",\"index\"].iloc[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823baeb0-7754-42c0-8dbf-0cef0bc19915",
   "metadata": {},
   "source": [
    "### microplastics treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea48b9fe-e1de-4321-9575-d34e29df59c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "microplastics_decisions_df = pd.read_csv(\"data/microplastics_decisions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe476f50-aaa4-4f3d-adb2-027ba7fef0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microplastics_decisions_df: updated 17 cells; skipped 1 rows.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# normalizer\n",
    "ekey = lambda s: str(s).strip().casefold()\n",
    "\n",
    "# copies + normalized keys\n",
    "A_index_df = A_index_df.copy()\n",
    "microplastics_decisions_df = microplastics_decisions_df.copy()\n",
    "\n",
    "A_index_df[\"prov_key\"] = A_index_df[\"provider name\"].map(ekey)\n",
    "microplastics_decisions_df[\"col_key\"] = microplastics_decisions_df[\"Provider name\"].map(ekey)\n",
    "microplastics_decisions_df[\"row_key\"] = microplastics_decisions_df[\"Input parameters names\"].map(ekey)\n",
    "\n",
    "# provider key -> list of integer indices in A (rows/cols)\n",
    "idx_map = (\n",
    "    A_index_df.groupby(\"prov_key\")[\"index\"]\n",
    "    .apply(lambda s: list(map(int, s)))\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# ensure numeric decision value\n",
    "microplastics_decisions_df[\"Linear Economy\"] = pd.to_numeric(\n",
    "    microplastics_decisions_df[\"Linear Economy\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# apply decisions: A[row, col] *= value\n",
    "n_pairs = 0\n",
    "skipped = 0\n",
    "\n",
    "for _, d in microplastics_decisions_df.iterrows():\n",
    "    x = d[\"Linear Economy\"]\n",
    "    if pd.isna(x):\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    row_idxs = idx_map.get(d[\"row_key\"], [])\n",
    "    col_idxs = idx_map.get(d[\"col_key\"], [])\n",
    "\n",
    "    if not row_idxs or not col_idxs:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    for ri in row_idxs:\n",
    "        for ci in col_idxs:\n",
    "            A[int(ri), int(ci)] = np.nan_to_num(A[int(ri), int(ci)]) * float(x)\n",
    "            n_pairs += 1\n",
    "\n",
    "print(f\"microplastics_decisions_df: updated {n_pairs} cells; skipped {skipped} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a877e1f-36b5-4b50-b0a4-4689f4f41b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
